# AI for the Arts and Humanities: A Critical Portfolio
**Author:** 2784359

## Project Overview
This portfolio documents my journey from basic Python literacy to a critical analysis of Machine Learning, framed through a Humanities lens. It is a record of my attempt to make sense of central coding concepts whilst being a critical observer of the AI tools (Microsoft/Github Copilot) assisting me.

The document serves two purposes: to demonstrate my competence in Python and Machine Learning theory, and to provide an honest reflection of the pros and cons involved in using Generative AI for academic work.

### Project Goals
* To prove I can read, interpret, and modify Python code for multimedia and data analysis.
* To demonstrate a basic understanding of how Machine Learning works.
* To document and reflect upon my experience of using AI assistance.
* To analyse and reflect upon the social, cultural, and structural implications of AI being used in the real world.
* To use what I have learned to propose, justify, and consider the implications of my own idea for an application that uses an LLM.

---

## Portfolio Structure

### 1. Foundational Skills (`coding_exercises.ipynb`)
This is where I started. The goal was to prove I could actually read code, not just copy-paste it.
* I tried to move away from technical computer science terms where I could, and move towards analogies and familiar themes to improve my understanding and memory of new ideas.
* It covers Python fundamentals (Variables, Loops, Functions) and multimedia processing (images/audio).

### 2. Critical Machine Learning (`Machine-Learning-by-Example-from-Start-to-End.ipynb`)
This was more of a deep dive that included more reflection on impacts and ideas. I took standard ML workflows (Housing Prices & MNIST Digits) and critiqued them and tried to understand them by involving my own thoughts and ideas.
* I used the Caledonian MacBrayne ferry crisis to explain Omitted Variable Bias (showing how AI can miss context).
* I argued that AI potentially "sanitises" culture by grouping art by Label rather than Vibe, for example by neglecting the nuance of different artworks.
* It documents my specific struggles with Tensorflow Playground, discussing my failures and successes.

### 3. Conceptual Design (`LLM_Design_Proposal.ipynb`)
*Note: This section is the final capstone (Part 4).*
A proposal for the **"Socratic Sparring Partner."** Instead of an AI that answers questions (which risks causing cognitive atrophy), this is a design for an AI specifically programmed to challenge the user, acting as a Devil's Advocate to improve critical thinking.

---

## Reflection on AI Assistance
I used AI tools (Microsoft/Github Copilot) throughout this project as a coding partner/teacher, and as a formatting assistant and note maker. Using AI was a bit of a double edged sword; sometimes it improved my understanding and saved me time; other times it made errors, confused me, and ended up wasting time.

### The Pros
* It helped me move from just "surviving" Python to actually learning it. Acting like a tutor, it patched small gaps in my knowledge instantly, meaning I didn't have to break flow to Google things. I could highlight a specific chunk that confused me, and it would explain line-by-line what was happening. It would often build those explanations directly into the code as comments, meaning when I looked back later (like in my codebook), I could see exactly what each bit did.
* The main benefit was the freedom to ramble. I could just relax and think out loud (using speech to text) in a "brain dump" - especially for the Machine Learning section - knowing the AI would capture my messy free flow of thoughts and organise them into themes for me. It acted as a formatting assistant and note maker, allowing me to be more genuinely thoughtful and creative without worrying about structure. It saved me time while letting my mind wander.
* It was great at adapting to my train of thought. When I used the "Immune System" analogy, it reworked its technical explanations to fit my metaphor, mapping it to concepts like *Domain Shift* and *Generalisation*. Being able to extend that metaphor myself became proof that I actually understood the underlying concept.

### The Cons
* The worst part was the time wasted and the hit to my confidence. When the AI hallucinated that code was working (when it wasn't), it would often "gaslight" me - insisting the code was correct and telling me to check my laptop settings or reinstall software. I’d find myself trapped in technical rabbit holes, putting blind faith in a machine that couldn't see. After hours chasing ghosts, I’d usually find out the error was just a simple syntax typo it had missed. It made me doubt myself before I doubted the code.
* Correcting its variable names became dull. The AI constantly forgot who the audience was, defaulting to "Computer Science" efficiency and trying to make every line as short as possible. I had to constantly fight it to keep my descriptive variable names (like `archive_box` instead of `x`) so that an amateur - like a Historian, or me! - could actually read and understand the work.
* It struggled to be a critic. It has a default "positivity bias" where it prioritises being nice over being useful. If I suggested a bad idea, it would generate code for a flawed approach rather than warning me it wouldn't work. It reinforced that I couldn't autopilot; without human oversight, it would have happily led the project off a cliff.
* The fear of it being wrong never really leaves. If I make a mistake myself, I lose a mark. But with AI, there is a constant anxiety that if I miss a hallucination, I might submit nonsense or face academic penalties. It raises the stakes of every error, meaning I could never fully relax.
* Finally, it made time management difficult. If I got lucky with a prompt, my working time was massively reduced. Conversely, if it sent me on a wild goose chase, a task would take twice as long as expected. It made predicting my output impossible; sometimes I would walk away from my work feeling very accomplished, and other times I would feel like no progress had been made at all.

### Workarounds & Takeaways
* I found that if I accused the AI of being wrong, it often got defensive or stubborn. It worked much better if I explained *why* I thought it was wrong and asked it some reflective questions; same as a human. If it got stuck in a loop, I learned to force a "break." I would change the topic entirely - asking it about the Arsenal game, the health benefits of fermented foods, or the origins of Halloween. When I returned to the code or the conversation after this "reset," it was often more responsive and open to new ideas - again probably the same as a human.
* When the AI blamed my laptop settings or gave me a solution I didn't trust, I stopped arguing with that specific chat. Instead, I would open 2 or 3 separate chats, ask them the same question, and ask them to "rank solutions by likelihood." It is energy inefficient and takes longer upfront, but it prevented me from rabbit-holing down a wrong path.
* Using speech-to-text I would speak aloud my thoughts freely and flowingly and make notes to myself and the AI would transcribe and then format my ideas into groups. This was excellent for creativity, but I noticed a flaw in how the AI listens. It tends to weight every idea equally. I might speak 2 sentences about a minor side-thought and 10 sentences about a central idea, and the AI would treat them as equally valid. I learned I had to be very explicit about which points were the core and which were spin-offs, otherwise it wouldn't prioritise.
* The AI had a default "positivity bias" that was genuinely annoying. It would often compliment a flawed idea just to be nice. I found that I had to explicitly tell it to be "harsh," "pernickety," or to "play Devil's Advocate." Once I gave it encouragement to be critical, the feedback became much more useful.
* Finally, a warning for future practice: AI is a massive distraction risk. When working with a human, the back-and-forth is natural. With AI, the slight delay in generating a reply - or the frustration of having to argue with it - often broke my flow. I found myself checking my phone or losing concentration during these micro-pauses. In the future, I will be more cautious about using it during deep-focus blocks, as the wee distractions add up to a lot of time wasted.